# üåü Chatbot en Arabe pour le Machine Learning üåü

---

## üìã √âtapes Principales du Projet

### **1. Scraping des Donn√©es**
- **But :** Collecter des questions-r√©ponses (Q/A) pertinentes pour le machine learning en anglais.
- **Sources utilis√©es :**
  - Turing Machine Learning Questions
  - MyGreatLearning Blog
- **Outils :** Utilisation de `Beautiful Soup` (Python) pour le scraping.

---

### **2. Nettoyage de la Base de Donn√©es**
- Suppression des caract√®res sp√©ciaux, des espaces inutiles et standardisation du format des donn√©es.
- Validation manuelle pour garantir la pertinence des donn√©es collect√©es.

---

### **3. Traduction Anglais ‚Üí Arabe**
- **Outils utilis√©s :** Trois mod√®les de traduction de Hugging Face :
  - [`Helsinki-NLP/opus-mt-en-ar`](https://huggingface.co/Helsinki-NLP/opus-mt-en-ar)
  - [`marefa-nlp/marefa-mt-en-ar`](https://huggingface.co/marefa-nlp/marefa-mt-en-ar)
  - [`t5-v1_1-base`](https://huggingface.co/t5-v1_1-base)
- **R√©sultat :** Le mod√®le [`marefa-nlp/marefa-mt-en-ar`](https://huggingface.co/marefa-nlp/marefa-mt-en-ar) a produit les meilleures traductions en termes de qualit√© et de pertinence.



![marefa-nlp/marefa-mt-en-ar](marefa1.jpg)


---

### **4. Nettoyage et Formatage des Textes en Arabe**
- **Outils :** API Gemini (via prompts avanc√©s) pour :
  - Reformuler et corriger les textes.
  - G√©n√©rer des donn√©es dans le format SQuAD (Q/A structur√©), adapt√© pour l'entra√Ænement des mod√®les.
- **Approche :** Multi-shot pour garantir des exemples vari√©s et coh√©rents.

  ![marefa-nlp/marefa-mt-en-ar](gemini.jpg)


---

### **5. Fine-tuning des Mod√®les LLM**
- **Mod√®les test√©s :**
  - **Finetuned Google AI Studio** (le meilleur parmi les trois mod√®les test√©s)
  - **AraBERT**
  - **T5-Small**
- **R√©sultat :** Bien que Finetuned Google AI Studio ait surpass√© les autres mod√®les en termes de performances, aucun des trois mod√®les n'a produit des r√©sultats satisfaisants pour la t√¢che sp√©cifique.

![Performance Comparison GIF](ai_studio.gif)



---

### **6. Utilisation de Ollama et Fine-tuning**
- **Plateforme utilis√©e :** Ollama
- **Mod√®les test√©s :**
  - `Mistral 7B`
  - `Llama 3.2`
- **√âtapes :**
  - T√©l√©chargement et fine-tuning des mod√®les avec des fichiers adapt√©s (`modelfiles`).
- **Comparaison :** Le mod√®le **Mistral 7B** a d√©montr√© des performances sup√©rieures en termes de scores WSSA et de retours qualitatifs.

  
![marefa-nlp/marefa-mt-en-ar](mistral.png)


---

### **7. Interface Utilisateur**
- Cr√©ation d'une interface utilisateur avec **Ollama Open UI** pour interagir avec le chatbot.
- Investigation des mod√®les directement via l'interface pour valider leurs r√©ponses et effectuer des comparaisons.

    ![marefa-nlp/marefa-mt-en-ar](interface.png)


---
## üõ†Ô∏è Lancer les Mod√®les Mistral 7B et Llama 3.2 avec Ollama et Docker

### 1. Installation d'Ollama
Avant de commencer, installez Ollama sur votre machine en suivant ces √©tapes :

- Rendez-vous sur le site officiel d‚ÄôOllama : [https://ollama.ai](https://ollama.ai).
- T√©l√©chargez la version d‚ÄôOllama correspondant √† votre syst√®me d‚Äôexploitation (Windows, macOS ou Linux).
- Installez l‚Äôoutil en suivant les instructions sp√©cifiques √† votre plateforme.

---

### 2. T√©l√©charger les Mod√®les
Une fois Ollama install√©, utilisez les commandes suivantes pour t√©l√©charger les mod√®les n√©cessaires :

#### T√©l√©charger le mod√®le **Mistral 7B** :
```bash
ollama pull mistral7b 
```

#### T√©l√©charger le mod√®le Llama 3.2 :
```bash
ollama pull llama3.2
```
---

### 3. Cr√©er et Ex√©cuter les Mod√®les
Pour fine-tuner ou personnaliser les mod√®les avec vos propres donn√©es, utilisez la commande suivante :
```bash
ollama create -f <path-to-modelfile> <nom-du-modele>
```

- Remplacez <path-to-modelfile> par le chemin vers le fichier contenant vos donn√©es ..
- Remplacez <nom-du-modele> par le nom que vous souhaitez attribuer au mod√®le.

#### Exemple :
```bash
ollama create -f ./data/mistral_Modelfile mistral7b-custom
```
---

### 4. Lancer les Mod√®les avec Docker et Open Web UI
Si vous souhaitez interagir avec les mod√®les via une interface graphique conviviale, utilisez Open Web UI avec Docker.

#### √âtape 1 : Lancer le Conteneur Docker
Ex√©cutez la commande suivante pour lancer le conteneur Docker :
```bash

docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway \
-v open-webui:/app/backend/data --name open-webui --restart always \
ghcr.io/open-webui/open-webui:main
```

#### √âtape 2 : V√©rifier le Conteneur
Assurez-vous que Docker est install√© et actif. V√©rifiez l‚Äô√©tat du conteneur avec cette commande :
```bash
docker ps
```
#### √âtape 3 : Acc√©der √† l‚ÄôInterface
Ouvrez votre navigateur web et rendez-vous √† l'adresse suivante :

http://localhost:3000

Vous pourrez alors interagir avec les mod√®les Mistral 7B et Llama 3.2 dans une interface utilisateur intuitive.

![Votre GIF ici](Generetive_AI_Ml (1).gif)

---


## üöÄ R√©sultats et Prochaines √âtapes
- **Meilleur mod√®le :** `Mistral 7B`
- **Prochaines √©tapes :**
  - Am√©liorer la robustesse du chatbot sur d'autres dialectes arabes.
  - Ajouter des m√©triques avanc√©es comme **BERTScore** pour √©valuer les r√©sultats.

---

## üìû Contact
**Auteur : [Votre Nom]**  
üìß **Email :** [votre.email@example.com]  
üåê **Portfolio :** [VotrePortfolio.com]  
üìÇ **GitHub :** [VotreGitHub](https://github.com/VotreGitHub)
