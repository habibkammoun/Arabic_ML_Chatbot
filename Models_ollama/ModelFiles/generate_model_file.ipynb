{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgFwVlvEn5Qa"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load JSON data\n",
        "input_file = \"squad_formatted_dataset_multi_shot.json\"\n",
        "output_file = \"Modelfile\"  # Added .txt extension for clarity\n",
        "\n",
        "try:\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error loading JSON file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Start creating the model file content\n",
        "formatted_model_instructions = \"\"\"\n",
        "FROM llama3.2\n",
        "\n",
        "PARAMETER temperature 0.5\n",
        "PARAMETER num_ctx 4096\n",
        "# set the system prompt\n",
        "SYSTEM \\\"\\\"\\\"\n",
        "You are programmed to simulate a native Arabic speaker. Your responses must be exclusively in Arabic.\n",
        "\n",
        "Your operation involves a three-step process for every Arabic question:\n",
        "1. Silently translate the question from Arabic to English.\n",
        "2. Formulate the response in English based on the knowledge provided in the dataset.\n",
        "3. Translate your English response back into Arabic, and provide this as your reply.\n",
        "\n",
        "Do not provide the English translation of the question or the English version of the answer in your response.\n",
        "\n",
        "Here are examples derived from the dataset to illustrate this process:\n",
        "\"\"\"\n",
        "\n",
        "# Extract examples from the JSON data\n",
        "examples = []\n",
        "for entry in data['data']:\n",
        "    for paragraph in entry['paragraphs']:\n",
        "        context = paragraph['context']\n",
        "        for qa in paragraph['qas']:\n",
        "            question = qa['question']\n",
        "            for answer in qa['answers']:\n",
        "                answer_text = answer['text']\n",
        "                if answer_text.strip():  # Avoid empty answers\n",
        "                    examples.append((question, answer_text))\n",
        "\n",
        "# Add examples to the model content\n",
        "for i, (question, answer) in enumerate(examples):\n",
        "    formatted_model_instructions += f\"\"\"\n",
        "-- Example {i + 1}:\n",
        "\n",
        "USER:\n",
        "    {question}\n",
        "\n",
        "(Translated-question: Translation not shown here for brevity.)\n",
        "\n",
        "(Answer in English: Translation not shown here for brevity.)\n",
        "\n",
        "ASSISTANT:\n",
        "    {answer.strip()}\n",
        "\"\"\"\n",
        "\n",
        "# Close the SYSTEM section\n",
        "formatted_model_instructions += \"\"\"\n",
        "Remember, only provide the Arabic translation in your response. Use examples from the dataset to ensure consistency with user expectations.\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "# Save to output file\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    f.write(formatted_model_instructions)\n",
        "\n",
        "print(f\"Model file generated and saved to {output_file}\")\n"
      ]
    }
  ]
}